<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Untagged on (base) shankarram:~</title>
    <link>http://localhost:44835/tags/untagged/</link>
    <description>Recent content in Untagged on (base) shankarram:~</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Fri, 30 Aug 2024 21:39:42 +0530</lastBuildDate>
    <atom:link href="http://localhost:44835/tags/untagged/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Drag Gan</title>
      <link>http://localhost:44835/posts/30-08-2024-drag-gan/</link>
      <pubDate>Fri, 30 Aug 2024 21:39:42 +0530</pubDate>
      <guid>http://localhost:44835/posts/30-08-2024-drag-gan/</guid>
      <description>DragGAN - Point-based Image Manipulation : Overview Generative Adversarial Networks (GANs) have revolutionized image generation over the past several years. Models like StyleGAN2 enable the creation of high-quality images that closely resemble the features of the training dataset. While advancements in architecture and training paradigms have significantly improved image generation quality, progress in manipulating generated images has been limited. For example, while a conditional GAN can generate an image of a person with specific attributes, altering these attributes in the generated image remains challenging.</description>
    </item>
  </channel>
</rss>
